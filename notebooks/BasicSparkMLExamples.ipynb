{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark ML Example\n",
    "\n",
    "This example is made with the goal to introduce ML with Spark from a Jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding resources "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "//Breeze from ScalaNLP: http://www.scalanlp.org/\n",
    "//classpath.addRepository(\"https://oss.sonatype.org/content/repositories/snapshots/\",\n",
    "//                        \"https://oss.sonatype.org/content/repositories/releases/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "//classpath.addRepository(\"http://dl.bintray.com/scalaz/releases\")\n",
    "//classpath.addRepository(\"https://repo1.maven.org/maven2/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the library dependencies\n",
    "\n",
    "Note that this is only for jupyter-scala, to be able to add these paths and libraries in a project you should do it with a build.sbt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 130 artifact(s)\n",
      "Adding 11 artifact(s)\n",
      "Adding 1 artifact(s)\n",
      "Adding 16 artifact(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classpath.add(\"org.apache.spark\" %% \"spark-core\" % \"1.6.0\")\n",
    "classpath.add(\"org.apache.spark\" %% \"spark-sql\" % \"1.6.0\")\n",
    "// classpath.add(\"org.apache.spark\" %% \"spark-hive\" % \"1.6.0\")\n",
    "classpath.add(\"org.apache.spark\" %% \"spark-streaming\" % \"1.6.0\")\n",
    "// classpath.add(\"org.apache.spark\" %% \"spark-streaming-kafka\" % \"1.6.0\")\n",
    "// classpath.add(\"org.apache.spark\" %% \"spark-streaming-flume\" % \"1.6.0\")\n",
    "classpath.add(\"org.apache.spark\" %% \"spark-mllib\" % \"1.6.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "//classpath.add(\"com.datastax.spark\" %% \"spark-cassandra-connector\" % \"1.3.0\")\n",
    "//classpath.add(\"org.apache.cassandra\" % \"cassandra-all\" % \"2.2.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 2 artifact(s)\n",
      "Adding 17 artifact(s)\n",
      "Adding 8 artifact(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classpath.add(\"org.scalanlp\" %% \"breeze\" % \"0.12\")\n",
    "classpath.add(\"org.scalanlp\" %% \"breeze-natives\" % \"0.12\")\n",
    "classpath.add(\"org.scalanlp\" %% \"breeze-viz\" % \"0.12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Spark and Spark SQL instances needed for the rest of the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36morg.apache.spark.{ SparkConf, SparkContext }\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.sql.SQLContext\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import org.apache.spark.{ SparkConf, SparkContext }\n",
    "import org.apache.spark.sql.SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "16/03/02 10:40:58 INFO SparkContext: Running Spark version 1.6.0\n",
      "16/03/02 10:40:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "16/03/02 10:40:58 WARN Utils: Your hostname, deepl resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "16/03/02 10:40:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "16/03/02 10:40:58 INFO SecurityManager: Changing view acls to: leo\n",
      "16/03/02 10:40:58 INFO SecurityManager: Changing modify acls to: leo\n",
      "16/03/02 10:40:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(leo); users with modify permissions: Set(leo)\n",
      "16/03/02 10:40:59 INFO Utils: Successfully started service 'sparkDriver' on port 35351.\n",
      "16/03/02 10:41:00 INFO Slf4jLogger: Slf4jLogger started\n",
      "16/03/02 10:41:00 INFO Remoting: Starting remoting\n",
      "16/03/02 10:41:00 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.0.2.15:36025]\n",
      "16/03/02 10:41:00 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 36025.\n",
      "16/03/02 10:41:00 INFO SparkEnv: Registering MapOutputTracker\n",
      "16/03/02 10:41:00 INFO SparkEnv: Registering BlockManagerMaster\n",
      "16/03/02 10:41:00 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-94a2080a-bf26-4d2c-a18b-8df415061ccb\n",
      "16/03/02 10:41:00 INFO MemoryStore: MemoryStore started with capacity 1603.1 MB\n",
      "16/03/02 10:41:00 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "16/03/02 10:41:01 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "16/03/02 10:41:01 INFO SparkUI: Started SparkUI at http://10.0.2.15:4040\n",
      "16/03/02 10:41:01 INFO Executor: Starting executor ID driver on host localhost\n",
      "16/03/02 10:41:01 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38128.\n",
      "16/03/02 10:41:01 INFO NettyBlockTransferService: Server created on 38128\n",
      "16/03/02 10:41:01 INFO BlockManagerMaster: Trying to register BlockManager\n",
      "16/03/02 10:41:01 INFO BlockManagerMasterEndpoint: Registering block manager localhost:38128 with 1603.1 MB RAM, BlockManagerId(driver, localhost, 38128)\n",
      "16/03/02 10:41:01 INFO BlockManagerMaster: Registered BlockManager\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36msparkConf\u001b[0m: \u001b[32mSparkConf\u001b[0m = org.apache.spark.SparkConf@24ba3f70\n",
       "\u001b[36msc\u001b[0m: \u001b[32mSparkContext\u001b[0m = org.apache.spark.SparkContext@1effa89e\n",
       "\u001b[36msqlContext\u001b[0m: \u001b[32mSQLContext\u001b[0m = org.apache.spark.sql.SQLContext@6c356b2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "//this is an example spark configuration, the setMaster is absolutely needed to be able to connect to the spark service\n",
    "val sparkConf = new SparkConf()\n",
    "      .setAppName(\"JupyterScalaTest\")\n",
    "      .setMaster(\"local\")\n",
    "\n",
    "val sc = new SparkContext(sparkConf)\n",
    "val sqlContext = new SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Spark ML\n",
    "### First example: Extimator, Transformer and Param\n",
    "\n",
    "The following example comes from the [official Spark 1.6.0 ML documentation ](http://spark.apache.org/docs/latest/ml-guide.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36morg.apache.spark.ml.classification.LogisticRegression\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.ml.param.ParamMap\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.mllib.linalg.{Vector, Vectors}\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.sql.Row\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.ml.param.ParamMap\n",
    "import org.apache.spark.mllib.linalg.{Vector, Vectors}\n",
    "import org.apache.spark.sql.Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training data from a list of (label, features) tuples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtraining\u001b[0m: \u001b[32morg\u001b[0m.\u001b[32mapache\u001b[0m.\u001b[32mspark\u001b[0m.\u001b[32msql\u001b[0m.\u001b[32mDataFrame\u001b[0m = [label: double, features: vector]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val training = sqlContext.createDataFrame(Seq(\n",
    "  (1.0, Vectors.dense(0.0, 1.1, 0.1)),\n",
    "  (0.0, Vectors.dense(2.0, 1.0, -1.0)),\n",
    "  (0.0, Vectors.dense(2.0, 1.3, 1.0)),\n",
    "  (1.0, Vectors.dense(0.0, 1.2, -0.5))\n",
    ")).toDF(\"label\", \"features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a LogisticRegression instance.  This instance is an Estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression parameters:\n",
      "elasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty (default: 0.0)\n",
      "featuresCol: features column name (default: features)\n",
      "fitIntercept: whether to fit an intercept term (default: true)\n",
      "labelCol: label column name (default: label)\n",
      "maxIter: maximum number of iterations (>= 0) (default: 100)\n",
      "predictionCol: prediction column name (default: prediction)\n",
      "probabilityCol: Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities (default: probability)\n",
      "rawPredictionCol: raw prediction (a.k.a. confidence) column name (default: rawPrediction)\n",
      "regParam: regularization parameter (>= 0) (default: 0.0)\n",
      "standardization: whether to standardize the training features before fitting the model (default: true)\n",
      "threshold: threshold in binary classification prediction, in range [0, 1] (default: 0.5)\n",
      "thresholds: Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values >= 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class' threshold. (undefined)\n",
      "tol: the convergence tolerance for iterative algorithms (default: 1.0E-6)\n",
      "weightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (default: )\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mlr\u001b[0m: \u001b[32mLogisticRegression\u001b[0m = logreg_141b3c4b147f"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val lr = new LogisticRegression()\n",
    "// Print out the parameters, documentation, and any default values.\n",
    "println(\"LogisticRegression parameters:\\n\" + lr.explainParams() + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may set parameters using setter methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres7\u001b[0m: \u001b[32mLogisticRegression\u001b[0m = logreg_141b3c4b147f"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr.setMaxIter(10)\n",
    "  .setRegParam(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn a LogisticRegression model.  This uses the parameters stored in lr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mmodel1\u001b[0m: \u001b[32morg\u001b[0m.\u001b[32mapache\u001b[0m.\u001b[32mspark\u001b[0m.\u001b[32mml\u001b[0m.\u001b[32mclassification\u001b[0m.\u001b[32mLogisticRegressionModel\u001b[0m = logreg_141b3c4b147f"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val model1 = lr.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since model1 is a Model (i.e., a Transformer produced by an Estimator), we can view the parameters it used during fit().\n",
    "\n",
    "This prints the parameter (name: value) pairs, where names are unique IDs for this LogisticRegression instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 was fit using parameters: {\n",
      "\tlogreg_141b3c4b147f-elasticNetParam: 0.0,\n",
      "\tlogreg_141b3c4b147f-featuresCol: features,\n",
      "\tlogreg_141b3c4b147f-fitIntercept: true,\n",
      "\tlogreg_141b3c4b147f-labelCol: label,\n",
      "\tlogreg_141b3c4b147f-maxIter: 10,\n",
      "\tlogreg_141b3c4b147f-predictionCol: prediction,\n",
      "\tlogreg_141b3c4b147f-probabilityCol: probability,\n",
      "\tlogreg_141b3c4b147f-rawPredictionCol: rawPrediction,\n",
      "\tlogreg_141b3c4b147f-regParam: 0.01,\n",
      "\tlogreg_141b3c4b147f-standardization: true,\n",
      "\tlogreg_141b3c4b147f-threshold: 0.5,\n",
      "\tlogreg_141b3c4b147f-tol: 1.0E-6,\n",
      "\tlogreg_141b3c4b147f-weightCol: \n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "println(\"Model 1 was fit using parameters: \" + model1.parent.extractParamMap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may alternatively specify parameters using a ParamMap, which supports several methods for specifying parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mparamMap\u001b[0m: \u001b[32mParamMap\u001b[0m = {\n",
       "\tlogreg_141b3c4b147f-maxIter: 30,\n",
       "\tlogreg_141b3c4b147f-regParam: 0.1,\n",
       "\tlogreg_141b3c4b147f-threshold: 0.55\n",
       "}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val paramMap = ParamMap(lr.maxIter -> 20)\n",
    "  .put(lr.maxIter, 30) // Specify 1 Param.  This overwrites the original maxIter.\n",
    "  .put(lr.regParam -> 0.1, lr.threshold -> 0.55) // Specify multiple Params."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also combine ParamMaps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mparamMap2\u001b[0m: \u001b[32mParamMap\u001b[0m = {\n",
       "\tlogreg_141b3c4b147f-probabilityCol: myProbability\n",
       "}\n",
       "\u001b[36mparamMapCombined\u001b[0m: \u001b[32mParamMap\u001b[0m = {\n",
       "\tlogreg_141b3c4b147f-maxIter: 30,\n",
       "\tlogreg_141b3c4b147f-probabilityCol: myProbability,\n",
       "\tlogreg_141b3c4b147f-regParam: 0.1,\n",
       "\tlogreg_141b3c4b147f-threshold: 0.55\n",
       "}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val paramMap2 = ParamMap(lr.probabilityCol -> \"myProbability\") // Change output column name\n",
    "val paramMapCombined = paramMap ++ paramMap2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now learn a new model using the paramMapCombined parameters.\n",
    "\n",
    "paramMapCombined overrides all parameters set earlier via lr.set* methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 was fit using parameters: {\n",
      "\tlogreg_141b3c4b147f-elasticNetParam: 0.0,\n",
      "\tlogreg_141b3c4b147f-featuresCol: features,\n",
      "\tlogreg_141b3c4b147f-fitIntercept: true,\n",
      "\tlogreg_141b3c4b147f-labelCol: label,\n",
      "\tlogreg_141b3c4b147f-maxIter: 30,\n",
      "\tlogreg_141b3c4b147f-predictionCol: prediction,\n",
      "\tlogreg_141b3c4b147f-probabilityCol: myProbability,\n",
      "\tlogreg_141b3c4b147f-rawPredictionCol: rawPrediction,\n",
      "\tlogreg_141b3c4b147f-regParam: 0.1,\n",
      "\tlogreg_141b3c4b147f-standardization: true,\n",
      "\tlogreg_141b3c4b147f-threshold: 0.55,\n",
      "\tlogreg_141b3c4b147f-tol: 1.0E-6,\n",
      "\tlogreg_141b3c4b147f-weightCol: \n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mmodel2\u001b[0m: \u001b[32morg\u001b[0m.\u001b[32mapache\u001b[0m.\u001b[32mspark\u001b[0m.\u001b[32mml\u001b[0m.\u001b[32mclassification\u001b[0m.\u001b[32mLogisticRegressionModel\u001b[0m = logreg_141b3c4b147f"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val model2 = lr.fit(training, paramMapCombined)\n",
    "println(\"Model 2 was fit using parameters: \" + model2.parent.extractParamMap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtest\u001b[0m: \u001b[32morg\u001b[0m.\u001b[32mapache\u001b[0m.\u001b[32mspark\u001b[0m.\u001b[32msql\u001b[0m.\u001b[32mDataFrame\u001b[0m = [label: double, features: vector]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val test = sqlContext.createDataFrame(Seq(\n",
    "  (1.0, Vectors.dense(-1.0, 1.5, 1.3)),\n",
    "  (0.0, Vectors.dense(3.0, 2.0, -0.1)),\n",
    "  (1.0, Vectors.dense(0.0, 2.2, -1.5))\n",
    ")).toDF(\"label\", \"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on test data using the Transformer.transform() method.\n",
    "\n",
    "LogisticRegression.transform will only use the 'features' column.\n",
    "\n",
    "Note that model2.transform() outputs a *'myProbability'* column instead of the usual *'probability'* column since we renamed the lr.probabilityCol parameter previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([-1.0,1.5,1.3], 1.0) -> prob=[0.05707304171033984,0.9429269582896601], prediction=1.0\n",
      "([3.0,2.0,-0.1], 0.0) -> prob=[0.9238522311704088,0.0761477688295912], prediction=0.0\n",
      "([0.0,2.2,-1.5], 1.0) -> prob=[0.10972776114779145,0.8902722388522085], prediction=1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2.transform(test)\n",
    "  .select(\"features\", \"label\", \"myProbability\", \"prediction\")\n",
    "  .collect()\n",
    "  .foreach { case Row(features: Vector, label: Double, prob: Vector, prediction: Double) =>\n",
    "    println(s\"($features, $label) -> prob=$prob, prediction=$prediction\")\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([-1.0,1.5,1.3], 1.0) -> prob=[0.0013759947069214356,0.9986240052930786], prediction=1.0\n",
      "([3.0,2.0,-0.1], 0.0) -> prob=[0.9816604009374171,0.018339599062582906], prediction=0.0\n",
      "([0.0,2.2,-1.5], 1.0) -> prob=[0.0016981475578358176,0.9983018524421641], prediction=1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1.transform(test)\n",
    "  .select(\"features\", \"label\", \"probability\", \"prediction\")\n",
    "  .collect()\n",
    "  .foreach { case Row(features: Vector, label: Double, prob: Vector, prediction: Double) =>\n",
    "    println(s\"($features, $label) -> prob=$prob, prediction=$prediction\")\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example: Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36morg.apache.spark.ml.Pipeline\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.ml.classification.LogisticRegression\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.ml.feature.{HashingTF, Tokenizer}\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.mllib.linalg.Vector\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.sql.Row\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.ml.feature.{HashingTF, Tokenizer}\n",
    "import org.apache.spark.mllib.linalg.Vector\n",
    "import org.apache.spark.sql.Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training documents from a list of (id, text, label) tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtraining\u001b[0m: \u001b[32morg\u001b[0m.\u001b[32mapache\u001b[0m.\u001b[32mspark\u001b[0m.\u001b[32msql\u001b[0m.\u001b[32mDataFrame\u001b[0m = [id: bigint, text: string, label: double]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val training = sqlContext.createDataFrame(Seq(\n",
    "  (0L, \"a b c d e spark\", 1.0),\n",
    "  (1L, \"b d\", 0.0),\n",
    "  (2L, \"spark f g h\", 1.0),\n",
    "  (3L, \"hadoop mapreduce\", 0.0)\n",
    ")).toDF(\"id\", \"text\", \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure an ML pipeline, which consists of three stages: tokenizer, hashingTF, and lr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtokenizer\u001b[0m: \u001b[32mTokenizer\u001b[0m = tok_b2cc633ac5de\n",
       "\u001b[36mhashingTF\u001b[0m: \u001b[32mHashingTF\u001b[0m = hashingTF_7a2a361c6479\n",
       "\u001b[36mlr\u001b[0m: \u001b[32mLogisticRegression\u001b[0m = logreg_b4713feb1c46\n",
       "\u001b[36mpipeline\u001b[0m: \u001b[32mPipeline\u001b[0m = pipeline_59400bbc551d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val tokenizer = new Tokenizer()\n",
    "  .setInputCol(\"text\")\n",
    "  .setOutputCol(\"words\")\n",
    "val hashingTF = new HashingTF()\n",
    "  .setNumFeatures(1000)\n",
    "  .setInputCol(tokenizer.getOutputCol)\n",
    "  .setOutputCol(\"features\")\n",
    "val lr = new LogisticRegression()\n",
    "  .setMaxIter(10)\n",
    "  .setRegParam(0.01)\n",
    "val pipeline = new Pipeline()\n",
    "  .setStages(Array(tokenizer, hashingTF, lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the pipeline to training documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mmodel\u001b[0m: \u001b[32morg\u001b[0m.\u001b[32mapache\u001b[0m.\u001b[32mspark\u001b[0m.\u001b[32mml\u001b[0m.\u001b[32mPipelineModel\u001b[0m = pipeline_59400bbc551d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val model = pipeline.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can optionally save the fitted pipeline to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.save(\"/tmp/spark-logistic-regression-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can also save this unfit pipeline to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline.save(\"/tmp/unfit-lr-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and load it back in during production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "java.lang.IllegalArgumentException: requirement failed: Error loading metadata: Expected class name org.apache.spark.ml.Pipeline but found class name org.apache.spark.ml.PipelineModel (requirement failed: Error loading metadata: Expected class name org.apache.spark.ml.Pipeline but found class name org.apache.spark.ml.PipelineModel)",
      "  scala.Predef$.require(Predef.scala:219)",
      "  org.apache.spark.ml.util.DefaultParamsReader$.loadMetadata(ReadWrite.scala:294)",
      "  org.apache.spark.ml.Pipeline$SharedReadWrite$.load(Pipeline.scala:253)",
      "  org.apache.spark.ml.Pipeline$PipelineReader.load(Pipeline.scala:203)",
      "  org.apache.spark.ml.Pipeline$PipelineReader.load(Pipeline.scala:197)",
      "  org.apache.spark.ml.util.MLReadable$class.load(ReadWrite.scala:176)",
      "  org.apache.spark.ml.Pipeline$.load(Pipeline.scala:187)",
      "  cmd22$$user$$anonfun$1.apply(Main.scala:25)",
      "  cmd22$$user$$anonfun$1.apply(Main.scala:24)"
     ]
    }
   ],
   "source": [
    "val sameModel = Pipeline.load(\"/tmp/spark-logistic-regression-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare test documents, which are unlabeled (id, text) tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtest\u001b[0m: \u001b[32morg\u001b[0m.\u001b[32mapache\u001b[0m.\u001b[32mspark\u001b[0m.\u001b[32msql\u001b[0m.\u001b[32mDataFrame\u001b[0m = [id: bigint, text: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val test = sqlContext.createDataFrame(Seq(\n",
    "  (4L, \"spark i j k\"),\n",
    "  (5L, \"l m n\"),\n",
    "  (6L, \"mapreduce spark\"),\n",
    "  (7L, \"apache hadoop\")\n",
    ")).toDF(\"id\", \"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on test documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, spark i j k) --> prob=[0.5406433544851431,0.45935664551485683], prediction=0.0\n",
      "(5, l m n) --> prob=[0.9334382627383263,0.06656173726167372], prediction=0.0\n",
      "(6, mapreduce spark) --> prob=[0.7799076868203894,0.2200923131796106], prediction=0.0\n",
      "(7, apache hadoop) --> prob=[0.9768636139518304,0.023136386048169637], prediction=0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.transform(test)\n",
    "  .select(\"id\", \"text\", \"probability\", \"prediction\")\n",
    "  .collect()\n",
    "  .foreach { case Row(id: Long, text: String, prob: Vector, prediction: Double) =>\n",
    "    println(s\"($id, $text) --> prob=$prob, prediction=$prediction\")\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Model  selection via Cross-Validation method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important task in ML is model selection, or using data to find the best model or parameters for a given task. This is also called tuning. Pipelines facilitate model selection by making it easy to tune an entire Pipeline at once, rather than tuning each element in the Pipeline separately.\n",
    "\n",
    "Currently, spark.ml supports model selection using the CrossValidator class, which takes an Estimator, a set of ParamMaps, and an Evaluator. CrossValidator begins by splitting the dataset into a set of folds which are used as separate training and test datasets; e.g., with k=3 folds, CrossValidator will generate 3 (training, test) dataset pairs, each of which uses 2/3 of the data for training and 1/3 for testing. CrossValidator iterates through the set of ParamMaps. For each ParamMap, it trains the given Estimator and evaluates it using the given Evaluator.\n",
    "\n",
    "The Evaluator can be a RegressionEvaluator for regression problems, a BinaryClassificationEvaluator for binary data, or a MultiClassClassificationEvaluator for multiclass problems. The default metric used to choose the best ParamMap can be overriden by the setMetric method in each of these evaluators.\n",
    "\n",
    "The ParamMap which produces the best evaluation metric (averaged over the k folds) is selected as the best model. CrossValidator finally fits the Estimator using the best ParamMap and the entire dataset.\n",
    "\n",
    "The following example demonstrates using CrossValidator to select from a grid of parameters. To help construct the parameter grid, we use the ParamGridBuilder utility.\n",
    "\n",
    "Note that cross-validation over a grid of parameters is expensive. E.g., in the example below, the parameter grid has 3 values for hashingTF.numFeatures and 2 values for lr.regParam, and CrossValidator uses 2 folds. This multiplies out to (3×2)×2=12 different models being trained. In realistic settings, it can be common to try many more parameters and use more folds (k=3 and k=10 are common). In other words, using CrossValidator can be very expensive. However, it is also a well-established method for choosing parameters which is more statistically sound than heuristic hand-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36morg.apache.spark.ml.Pipeline\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.ml.classification.LogisticRegression\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.ml.evaluation.BinaryClassificationEvaluator\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.ml.feature.{HashingTF, Tokenizer}\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.mllib.linalg.Vector\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.sql.Row\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n",
    "import org.apache.spark.ml.feature.{HashingTF, Tokenizer}\n",
    "import org.apache.spark.ml.tuning.{ParamGridBuilder, CrossValidator}\n",
    "import org.apache.spark.mllib.linalg.Vector\n",
    "import org.apache.spark.sql.Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training data from a list of (id, text, label) tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtraining\u001b[0m: \u001b[32morg\u001b[0m.\u001b[32mapache\u001b[0m.\u001b[32mspark\u001b[0m.\u001b[32msql\u001b[0m.\u001b[32mDataFrame\u001b[0m = [id: bigint, text: string, label: double]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val training = sqlContext.createDataFrame(Seq(\n",
    "  (0L, \"a b c d e spark\", 1.0),\n",
    "  (1L, \"b d\", 0.0),\n",
    "  (2L, \"spark f g h\", 1.0),\n",
    "  (3L, \"hadoop mapreduce\", 0.0),\n",
    "  (4L, \"b spark who\", 1.0),\n",
    "  (5L, \"g d a y\", 0.0),\n",
    "  (6L, \"spark fly\", 1.0),\n",
    "  (7L, \"was mapreduce\", 0.0),\n",
    "  (8L, \"e spark program\", 1.0),\n",
    "  (9L, \"a e c l\", 0.0),\n",
    "  (10L, \"spark compile\", 1.0),\n",
    "  (11L, \"hadoop software\", 0.0)\n",
    ")).toDF(\"id\", \"text\", \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure an ML pipeline, which consists of three stages: tokenizer, hashingTF, and lr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtokenizer\u001b[0m: \u001b[32mTokenizer\u001b[0m = tok_1521227f7244\n",
       "\u001b[36mhashingTF\u001b[0m: \u001b[32mHashingTF\u001b[0m = hashingTF_8283fa2c8032\n",
       "\u001b[36mlr\u001b[0m: \u001b[32mLogisticRegression\u001b[0m = logreg_02308251a5f5\n",
       "\u001b[36mpipeline\u001b[0m: \u001b[32mPipeline\u001b[0m = pipeline_6a7de8af7d90"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val tokenizer = new Tokenizer()\n",
    "  .setInputCol(\"text\")\n",
    "  .setOutputCol(\"words\")\n",
    "val hashingTF = new HashingTF()\n",
    "  .setInputCol(tokenizer.getOutputCol)\n",
    "  .setOutputCol(\"features\")\n",
    "val lr = new LogisticRegression()\n",
    "  .setMaxIter(10)\n",
    "val pipeline = new Pipeline()\n",
    "  .setStages(Array(tokenizer, hashingTF, lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
    "\n",
    "With 3 values for hashingTF.numFeatures and 2 values for lr.regParam, this grid will have 3 x 2 = 6 parameter settings for CrossValidator to choose from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mparamGrid\u001b[0m: \u001b[32mArray\u001b[0m[\u001b[32mParamMap\u001b[0m] = \u001b[33mArray\u001b[0m(\n",
       "  {\n",
       "\thashingTF_8283fa2c8032-numFeatures: 10,\n",
       "\tlogreg_02308251a5f5-regParam: 0.1\n",
       "},\n",
       "  {\n",
       "\thashingTF_8283fa2c8032-numFeatures: 10,\n",
       "\tlogreg_02308251a5f5-regParam: 0.01\n",
       "},\n",
       "  {\n",
       "\thashingTF_8283fa2c8032-numFeatures: 100,\n",
       "\tlogreg_02308251a5f5-regParam: 0.1\n",
       "},\n",
       "  {\n",
       "\thashingTF_8283fa2c8032-numFeatures: 100,\n",
       "\tlogreg_02308251a5f5-regParam: 0.01\n",
       "},\n",
       "  {\n",
       "\thashingTF_8283fa2c8032-numFeatures: 1000,\n",
       "\tlogreg_02308251a5f5-regParam: 0.1\n",
       "\u001b[33m...\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val paramGrid = new ParamGridBuilder()\n",
    "  .addGrid(hashingTF.numFeatures, Array(10, 100, 1000))\n",
    "  .addGrid(lr.regParam, Array(0.1, 0.01))\n",
    "  .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "\n",
    "This will allow us to jointly choose parameters for all Pipeline stages.\n",
    "\n",
    "A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
    "\n",
    "Note that the evaluator here is a BinaryClassificationEvaluator and its default metric is areaUnderROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mcv\u001b[0m: \u001b[32mCrossValidator\u001b[0m = cv_b5cb0e750640"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val cv = new CrossValidator()\n",
    "  .setEstimator(pipeline)\n",
    "  .setEvaluator(new BinaryClassificationEvaluator)\n",
    "  .setEstimatorParamMaps(paramGrid)\n",
    "  .setNumFolds(2) // Use 3+ in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run cross-validation, and choose the best set of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mcvModel\u001b[0m: \u001b[32morg\u001b[0m.\u001b[32mapache\u001b[0m.\u001b[32mspark\u001b[0m.\u001b[32mml\u001b[0m.\u001b[32mtuning\u001b[0m.\u001b[32mCrossValidatorModel\u001b[0m = cv_b5cb0e750640"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val cvModel = cv.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare test documents, which are unlabeled (id, text) tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtest\u001b[0m: \u001b[32morg\u001b[0m.\u001b[32mapache\u001b[0m.\u001b[32mspark\u001b[0m.\u001b[32msql\u001b[0m.\u001b[32mDataFrame\u001b[0m = [id: bigint, text: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val test = sqlContext.createDataFrame(Seq(\n",
    "  (4L, \"spark i j k\"),\n",
    "  (5L, \"l m n\"),\n",
    "  (6L, \"mapreduce spark\"),\n",
    "  (7L, \"apache hadoop\")\n",
    ")).toDF(\"id\", \"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on test documents. cvModel uses the best model found (lrModel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, spark i j k) --> prob=[0.24804795226775067,0.7519520477322493], prediction=1.0\n",
      "(5, l m n) --> prob=[0.9647209186740324,0.0352790813259676], prediction=0.0\n",
      "(6, mapreduce spark) --> prob=[0.4248344997494982,0.5751655002505017], prediction=1.0\n",
      "(7, apache hadoop) --> prob=[0.6899594200690093,0.3100405799309907], prediction=0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cvModel.transform(test)\n",
    "  .select(\"id\", \"text\", \"probability\", \"prediction\")\n",
    "  .collect()\n",
    "  .foreach { case Row(id: Long, text: String, prob: Vector, prediction: Double) =>\n",
    "    println(s\"($id, $text) --> prob=$prob, prediction=$prediction\")\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: model selection via train validation split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to CrossValidator Spark also offers TrainValidationSplit for hyper-parameter tuning. \n",
    "\n",
    "TrainValidationSplit only evaluates each combination of parameters once as opposed to k times in case of CrossValidator. It is therefore less expensive, but will not produce as reliable results when the training dataset is not sufficiently large.\n",
    "\n",
    "TrainValidationSplit takes an Estimator, a set of ParamMaps provided in the estimatorParamMaps parameter, and an Evaluator. It begins by splitting the dataset into two parts using trainRatio parameter which are used as separate training and test datasets. For example with *trainRatio=0.75* (default), TrainValidationSplit will generate a training and test dataset pair where 75% of the data is used for training and 25% for validation. Similar to CrossValidator, TrainValidationSplit also iterates through the set of ParamMaps. For each combination of parameters, it trains the given Estimator and evaluates it using the given Evaluator. The ParamMap which produces the best evaluation metric is selected as the best option. TrainValidationSplit finally fits the Estimator using the best ParamMap and the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36morg.apache.spark.ml.evaluation.RegressionEvaluator\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.ml.regression.LinearRegression\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit}\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import org.apache.spark.ml.evaluation.RegressionEvaluator\n",
    "import org.apache.spark.ml.regression.LinearRegression\n",
    "import org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdata\u001b[0m: \u001b[32morg\u001b[0m.\u001b[32mapache\u001b[0m.\u001b[32mspark\u001b[0m.\u001b[32msql\u001b[0m.\u001b[32mDataFrame\u001b[0m = [label: double, features: vector]\n",
       "\u001b[36mtraining\u001b[0m: \u001b[32morg\u001b[0m.\u001b[32mapache\u001b[0m.\u001b[32mspark\u001b[0m.\u001b[32msql\u001b[0m.\u001b[32mDataFrame\u001b[0m = [label: double, features: vector]\n",
       "\u001b[36mtest\u001b[0m: \u001b[32morg\u001b[0m.\u001b[32mapache\u001b[0m.\u001b[32mspark\u001b[0m.\u001b[32msql\u001b[0m.\u001b[32mDataFrame\u001b[0m = [label: double, features: vector]\n",
       "\u001b[36mlir\u001b[0m: \u001b[32mLogisticRegression\u001b[0m = logreg_594edaf1ad50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val data = sqlContext.read.format(\"libsvm\").load(\"/home/leo/installers/spark-1.6.0-bin-hadoop2.6/data/mllib/sample_libsvm_data.txt\")\n",
    "val Array(training, test) = data.randomSplit(Array(0.9, 0.1), seed = 12345)\n",
    "\n",
    "// val lir = new LinearRegression() // this fails -> bug in spark ml so I' ll use logistic\n",
    "val lir = new LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0,(692,[127,128,129,130,131,154,155,156,157,158,159,181,182,183,184,185,186,187,188,189,207,208,209,210,211,212,213,214,215,216,217,235,236,237,238,239,240,241,242,243,244,245,262,263,264,265,266,267,268,269,270,271,272,273,289,290,291,292,293,294,295,296,297,300,301,302,316,317,318,319,320,321,328,329,330,343,344,345,346,347,348,349,356,357,358,371,372,373,374,384,385,386,399,400,401,412,413,414,426,427,428,429,440,441,442,454,455,456,457,466,467,468,469,470,482,483,484,493,494,495,496,497,510,511,512,520,521,522,523,538,539,540,547,548,549,550,566,567,568,569,570,571,572,573,574,575,576,577,578,594,595,596,597,598,599,600,601,602,603,604,622,623,624,625,626,627,628,629,630,651,652,653,654,655,656,657],[51.0,159.0,253.0,159.0,50.0,48.0,238.0,252.0,252.0,252.0,237.0,54.0,227.0,253.0,252.0,239.0,233.0,252.0,57.0,6.0,10.0,60.0,224.0,252.0,253.0,252.0,202.0,84.0,252.0,253.0,122.0,163.0,252.0,252.0,252.0,253.0,252.0,252.0,96.0,189.0,253.0,167.0,51.0,238.0,253.0,253.0,190.0,114.0,253.0,228.0,47.0,79.0,255.0,168.0,48.0,238.0,252.0,252.0,179.0,12.0,75.0,121.0,21.0,253.0,243.0,50.0,38.0,165.0,253.0,233.0,208.0,84.0,253.0,252.0,165.0,7.0,178.0,252.0,240.0,71.0,19.0,28.0,253.0,252.0,195.0,57.0,252.0,252.0,63.0,253.0,252.0,195.0,198.0,253.0,190.0,255.0,253.0,196.0,76.0,246.0,252.0,112.0,253.0,252.0,148.0,85.0,252.0,230.0,25.0,7.0,135.0,253.0,186.0,12.0,85.0,252.0,223.0,7.0,131.0,252.0,225.0,71.0,85.0,252.0,145.0,48.0,165.0,252.0,173.0,86.0,253.0,225.0,114.0,238.0,253.0,162.0,85.0,252.0,249.0,146.0,48.0,29.0,85.0,178.0,225.0,253.0,223.0,167.0,56.0,85.0,252.0,252.0,252.0,229.0,215.0,252.0,252.0,252.0,196.0,130.0,28.0,199.0,252.0,252.0,253.0,252.0,252.0,233.0,145.0,25.0,128.0,252.0,253.0,252.0,141.0,37.0])]\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "println(data.first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
    "TrainValidationSplit will try all combinations of values and determine best model using\n",
    "the evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mparamGrid\u001b[0m: \u001b[32mArray\u001b[0m[\u001b[32mParamMap\u001b[0m] = \u001b[33mArray\u001b[0m(\n",
       "  {\n",
       "\tlogreg_594edaf1ad50-elasticNetParam: 0.0,\n",
       "\tlogreg_594edaf1ad50-fitIntercept: true,\n",
       "\tlogreg_594edaf1ad50-regParam: 0.1\n",
       "},\n",
       "  {\n",
       "\tlogreg_594edaf1ad50-elasticNetParam: 0.5,\n",
       "\tlogreg_594edaf1ad50-fitIntercept: true,\n",
       "\tlogreg_594edaf1ad50-regParam: 0.1\n",
       "},\n",
       "  {\n",
       "\tlogreg_594edaf1ad50-elasticNetParam: 1.0,\n",
       "\tlogreg_594edaf1ad50-fitIntercept: true,\n",
       "\tlogreg_594edaf1ad50-regParam: 0.1\n",
       "},\n",
       "  {\n",
       "\tlogreg_594edaf1ad50-elasticNetParam: 0.0,\n",
       "\tlogreg_594edaf1ad50-fitIntercept: true,\n",
       "\tlogreg_594edaf1ad50-regParam: 0.01\n",
       "\u001b[33m...\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val paramGrid = new ParamGridBuilder()\n",
    "  .addGrid(lir.regParam, Array(0.1, 0.01))\n",
    "  .addGrid(lir.fitIntercept)\n",
    "  .addGrid(lir.elasticNetParam, Array(0.0, 0.5, 1.0))\n",
    "  .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the estimator is simply the linear regression.\n",
    "\n",
    "A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, and an Evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtrainValidationSplit\u001b[0m: \u001b[32mTrainValidationSplit\u001b[0m = tvs_bb15903fef3c"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val trainValidationSplit = new TrainValidationSplit()\n",
    "  .setEstimator(lir)\n",
    "  .setEvaluator(new RegressionEvaluator)\n",
    "  .setEstimatorParamMaps(paramGrid)\n",
    "  // 80% of the data will be used for training and the remaining 20% for validation.\n",
    "  .setTrainRatio(0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run train validation split, and choose the best set of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mmodel\u001b[0m: \u001b[32morg\u001b[0m.\u001b[32mapache\u001b[0m.\u001b[32mspark\u001b[0m.\u001b[32mml\u001b[0m.\u001b[32mtuning\u001b[0m.\u001b[32mTrainValidationSplitModel\u001b[0m = tvs_bb15903fef3c"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val model = trainValidationSplit.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on test data. model is the model with combination of parameters\n",
    "that performed best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|            features|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|(692,[151,152,153...|  1.0|       1.0|\n",
      "|(692,[154,155,156...|  0.0|       0.0|\n",
      "|(692,[127,128,129...|  1.0|       1.0|\n",
      "|(692,[127,128,129...|  1.0|       1.0|\n",
      "|(692,[95,96,97,12...|  0.0|       0.0|\n",
      "|(692,[128,129,130...|  1.0|       1.0|\n",
      "|(692,[129,130,131...|  1.0|       1.0|\n",
      "+--------------------+-----+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.transform(test)\n",
    "  .select(\"features\", \"label\", \"prediction\")\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.11",
   "language": "scala211",
   "name": "scala211"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "pygments_lexer": "scala",
   "version": "2.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
